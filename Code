import os
import pandas as pd
from PIL import Image
import numpy as np
import sklearn
df_train = pd.read_csv('/Users/yangzhang/Documents/文稿 - YangZhang的MacBook Pro/Data Science/Machine Learning/sansan-001/train.csv')
df_train.head()
df_train.shape
row = df_train.iloc[0,:]
row
DIR_IMAGES = '/Users/yangzhang/Documents/文稿 - YangZhang的MacBook Pro/Data Science/Machine Learning/sansan-001/images'
img = Image.open(os.path.join(DIR_IMAGES, row.filename))
img = img.crop((row.left, row.top, row.right, row.bottom))
img
df_test = pd.read_csv('/Users/yangzhang/Documents/文稿 - YangZhang的MacBook Pro/Data Science/Machine Learning/sansan-001/test.csv')
df_test.head()
df_test.shape
df_train=df_train.sample(500,random_state=0)
df_test=df_test.sample(100,random_state=0)
img
img = img.convert('L')
img
IMG_SIZE = 100
img = img.resize((IMG_SIZE,IMG_SIZE),resample = Image.BICUBIC)
img
IMG_SIZE = 100
img = img.resize((IMG_SIZE, IMG_SIZE),resample = Image.BICUBIC)
img
x = np.asarray(img,dtype = np.float)
x.shape

x

x = x.flatten()
x

X_train = []
for i, row in df_train.iterrows():
    img = Image.open(os.path.join(DIR_IMAGES, row.filename))
    img = img.crop((row.left, row.top, row.right, row.bottom))
    img = img.convert('L')
    img = img.resize((IMG_SIZE,IMG_SIZE),resample = Image.BICUBIC)
    
    x = np.asarray(img,dtype = np.float)
    x = x.flatten()
    X_train.append(x)
X_train = np.array(X_train)

X_test = []
for i, row in df_test.iterrows():
    img = Image.open(os.path.join(DIR_IMAGES, row.filename))
    img = img.crop((row.left, row.top, row.right, row.bottom))
    img = img.convert('L')
    img = img.resize((IMG_SIZE,IMG_SIZE),resample=Image.BICUBIC)
    
    x = np.asarray(img, dtype=np.float)
    x = x.flatten()
    X_test.append(x)
X_test = np.array(X_test)

columns = ['company_name','full_name','position_name','address','phone_number','fax','mobile','email','url']
Y_train = df_train[columns].values

from sklearn.model_selection import train_test_split
X_dev, X_val, Y_dev, Y_val = train_test_split(X_train,Y_train,train_size=0.8, random_state=0)

print (X_dev.shape, Y_dev.shape)
print (X_val.shape, Y_val.shape)

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaler.fit(X_dev)

X_dev_scaled = scaler.transform(X_dev)

X_dev_scaled.mean(axis=0)

X_dev_scaled.var(axis=0)

from sklearn.decomposition import PCA
decomposer = PCA(n_components=10, random_state=0)
decomposer.fit(X_dev_scaled)

X_dev_pca = decomposer.transform(X_dev_scaled)

X_dev_pca = decomposer.transform(X_dev_scaled)

print (X_dev_pca.shape)

X_val_scaled = scaler.transform(X_val)
X_val_pca = decomposer.transform(X_val_scaled)

from sklearn.linear_model import LogisticRegression

classifiers = []
for j in range(Y_dev.shape[1]):
    y = Y_dev[:,j]
    classifier = LogisticRegression(penalty = 'l2', C = 0.01)
    classifier.fit(X_dev_pca,y)
    classifiers.append(classifier)

Y_val_pred = np.zeros(Y_val.shape)
for j in range(Y_dev.shape[1]):
    classifier = classifiers[j]
    y = classifier.predict_proba(X_val_pca)[:,1]
    Y_val_pred[:,j] = y

Y_val_pred.shape

from sklearn.metrics import roc_auc_score
roc_auc_score(Y_val,Y_val_pred,average='macro')

from sklearn.multiclass import OneVsRestClassifier

classifier = OneVsRestClassifier(LogisticRegression(penalty='l2',C=0.01))
classifier.fit(X_dev_pca,Y_dev)
Y_val_pred = classifier.predict_proba(X_val_pca)

roc_auc_score(Y_val,Y_val_pred,average='macro')

from sklearn.pipeline import Pipeline

steps = [('scaler',StandardScaler()),('decomposer',PCA(10,random_state=0)),
        ('classifier',OneVsRestClassifier(LogisticRegression(penalty='l2')))]
pipeline = Pipeline(steps)

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import make_scorer

params = {'classifier__estimator__C':[0.01,0.1,1.0,10.,100.]}
scorer = make_scorer(roc_auc_score,average='macro',needs_proba=True)
predictor = GridSearchCV(pipeline,params,cv=5, scoring=scorer)

predictor.fit(X_dev,Y_dev)

predictor.best_params_

Y_val_pred = predictor.predict_proba(X_val)
roc_auc_score(Y_val,Y_val_pred,average='macro')

param = {'classifier__estimator__C': [0.01,0.1,1.0,10.,100.],
        'decomposer__n_components':[10,20,50]}

predictor = GridSearchCV(pipeline, params,cv=5,scoring=scorer)
predictor.fit(X_dev,Y_dev)

predictor.best_params_

Y_val_pred = predictor.predict_proba(X_val)
roc_auc_score(Y_val,Y_val_pred,average='macro')

final_predictor = predictor.best_estimator_
final_predictor.fit(X_train,Y_train)

Y_test_pred = final_predictor.predict_proba(X_test)
np.savetxt('submission.dat',Y_test_pred,fmt='%.6f')
